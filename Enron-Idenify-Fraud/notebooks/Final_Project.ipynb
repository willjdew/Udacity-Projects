{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Enron Email Person of Interest Identification </h1> </center>\n",
    "\n",
    "Enron was an energy company that was one of the largest companies in the US when it filled for bankruptcy in 2002.  This was due to widespread corporate fraud.  Emails and finacial data entered the public record after the Federal investigation.  I will be looking at this data to see if I can create an algorithm that can help predict Persons of Interest in the Enron scandal\n",
    "\n",
    "(The Enron email + financial dataset, along with several provisional functions used in this report, is available on [Udacity's GitHub](https://github.com/udacity/ud120-projects).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "import tester\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Investigation and Cleaning </h2>\n",
    "\n",
    "The first thing that needs to be done is to look over the data and figure out what is in it and see if there are any errors.  The data is provided in a python dictionary which I will convert to pandas dataframe for easier data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "payment_columns = ['salary',\n",
    "                   'bonus',\n",
    "                   'long_term_incentive',\n",
    "                   'deferred_income',\n",
    "                   'deferral_payments',\n",
    "                   'loan_advances',\n",
    "                   'other',\n",
    "                   'expenses',\n",
    "                   'director_fees',\n",
    "                   'total_payments']\n",
    "\n",
    "stock_columns = ['exercised_stock_options',\n",
    "                 'restricted_stock',\n",
    "                 'restricted_stock_deferred',\n",
    "                 'total_stock_value']\n",
    "\n",
    "email_columns = ['to_messages',\n",
    "                 'from_messages',\n",
    "                 'from_poi_to_this_person',\n",
    "                 'from_this_person_to_poi',\n",
    "                 'shared_receipt_with_poi']             \n",
    "              \n",
    "features_list = ['poi'] + payment_columns + stock_columns + email_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# transfer dictionary to dataframe for easier data manipulation\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "# replace all 'NaN' with numpy 'nan'\n",
    "df = df.replace('NaN', np.nan)\n",
    "# reorder dataframe columns to match features_list\n",
    "df = df[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null bool\n",
      "salary                       95 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "other                        93 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "dtypes: bool(1), float64(19)\n",
      "memory usage: 22.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>False</td>\n",
       "      <td>201955.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>False</td>\n",
       "      <td>477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>-560222.0</td>\n",
       "      <td>5243487.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>False</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>False</td>\n",
       "      <td>239671.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>63014.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      poi    salary      bonus  long_term_incentive  \\\n",
       "ALLEN PHILLIP K     False  201955.0  4175000.0             304805.0   \n",
       "BADUM JAMES P       False       NaN        NaN                  NaN   \n",
       "BANNANTINE JAMES M  False     477.0        NaN                  NaN   \n",
       "BAXTER JOHN C       False  267102.0  1200000.0            1586055.0   \n",
       "BAY FRANKLIN R      False  239671.0   400000.0                  NaN   \n",
       "\n",
       "                    deferred_income  deferral_payments  loan_advances  \\\n",
       "ALLEN PHILLIP K          -3081055.0          2869717.0            NaN   \n",
       "BADUM JAMES P                   NaN           178980.0            NaN   \n",
       "BANNANTINE JAMES M          -5104.0                NaN            NaN   \n",
       "BAXTER JOHN C            -1386055.0          1295738.0            NaN   \n",
       "BAY FRANKLIN R            -201641.0           260455.0            NaN   \n",
       "\n",
       "                        other  expenses  director_fees  total_payments  \\\n",
       "ALLEN PHILLIP K         152.0   13868.0            NaN       4484442.0   \n",
       "BADUM JAMES P             NaN    3486.0            NaN        182466.0   \n",
       "BANNANTINE JAMES M   864523.0   56301.0            NaN        916197.0   \n",
       "BAXTER JOHN C       2660303.0   11200.0            NaN       5634343.0   \n",
       "BAY FRANKLIN R           69.0  129142.0            NaN        827696.0   \n",
       "\n",
       "                    exercised_stock_options  restricted_stock  \\\n",
       "ALLEN PHILLIP K                   1729541.0          126027.0   \n",
       "BADUM JAMES P                      257817.0               NaN   \n",
       "BANNANTINE JAMES M                4046157.0         1757552.0   \n",
       "BAXTER JOHN C                     6680544.0         3942714.0   \n",
       "BAY FRANKLIN R                          NaN          145796.0   \n",
       "\n",
       "                    restricted_stock_deferred  total_stock_value  to_messages  \\\n",
       "ALLEN PHILLIP K                     -126027.0          1729541.0       2902.0   \n",
       "BADUM JAMES P                             NaN           257817.0          NaN   \n",
       "BANNANTINE JAMES M                  -560222.0          5243487.0        566.0   \n",
       "BAXTER JOHN C                             NaN         10623258.0          NaN   \n",
       "BAY FRANKLIN R                       -82782.0            63014.0          NaN   \n",
       "\n",
       "                    from_messages  from_poi_to_this_person  \\\n",
       "ALLEN PHILLIP K            2195.0                     47.0   \n",
       "BADUM JAMES P                 NaN                      NaN   \n",
       "BANNANTINE JAMES M           29.0                     39.0   \n",
       "BAXTER JOHN C                 NaN                      NaN   \n",
       "BAY FRANKLIN R                NaN                      NaN   \n",
       "\n",
       "                    from_this_person_to_poi  shared_receipt_with_poi  \n",
       "ALLEN PHILLIP K                        65.0                   1407.0  \n",
       "BADUM JAMES P                           NaN                      NaN  \n",
       "BANNANTINE JAMES M                      0.0                    465.0  \n",
       "BAXTER JOHN C                           NaN                      NaN  \n",
       "BAY FRANKLIN R                          NaN                      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.250000e+02</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.260000e+02</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.621943e+05</td>\n",
       "      <td>2.374235e+06</td>\n",
       "      <td>1.470361e+06</td>\n",
       "      <td>-1.140475e+06</td>\n",
       "      <td>1.642674e+06</td>\n",
       "      <td>4.196250e+07</td>\n",
       "      <td>9.190650e+05</td>\n",
       "      <td>1.087289e+05</td>\n",
       "      <td>1.668049e+05</td>\n",
       "      <td>5.081526e+06</td>\n",
       "      <td>5.987054e+06</td>\n",
       "      <td>2.321741e+06</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>6.773957e+06</td>\n",
       "      <td>2073.860465</td>\n",
       "      <td>608.790698</td>\n",
       "      <td>64.895349</td>\n",
       "      <td>41.232558</td>\n",
       "      <td>1176.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.716369e+06</td>\n",
       "      <td>1.071333e+07</td>\n",
       "      <td>5.942759e+06</td>\n",
       "      <td>4.025406e+06</td>\n",
       "      <td>5.161930e+06</td>\n",
       "      <td>4.708321e+07</td>\n",
       "      <td>4.589253e+06</td>\n",
       "      <td>5.335348e+05</td>\n",
       "      <td>3.198914e+05</td>\n",
       "      <td>2.906172e+07</td>\n",
       "      <td>3.106201e+07</td>\n",
       "      <td>1.251828e+07</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>3.895777e+07</td>\n",
       "      <td>2582.700981</td>\n",
       "      <td>1841.033949</td>\n",
       "      <td>86.979244</td>\n",
       "      <td>100.073111</td>\n",
       "      <td>1178.317641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.118160e+05</td>\n",
       "      <td>4.312500e+05</td>\n",
       "      <td>2.812500e+05</td>\n",
       "      <td>-6.948620e+05</td>\n",
       "      <td>8.157300e+04</td>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>1.215000e+03</td>\n",
       "      <td>2.261400e+04</td>\n",
       "      <td>9.878400e+04</td>\n",
       "      <td>3.944750e+05</td>\n",
       "      <td>5.278862e+05</td>\n",
       "      <td>2.540180e+05</td>\n",
       "      <td>-3.896218e+05</td>\n",
       "      <td>4.945102e+05</td>\n",
       "      <td>541.250000</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>249.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.599960e+05</td>\n",
       "      <td>7.693750e+05</td>\n",
       "      <td>4.420350e+05</td>\n",
       "      <td>-1.597920e+05</td>\n",
       "      <td>2.274490e+05</td>\n",
       "      <td>4.176250e+07</td>\n",
       "      <td>5.238200e+04</td>\n",
       "      <td>4.695000e+04</td>\n",
       "      <td>1.085790e+05</td>\n",
       "      <td>1.101393e+06</td>\n",
       "      <td>1.310814e+06</td>\n",
       "      <td>4.517400e+05</td>\n",
       "      <td>-1.469750e+05</td>\n",
       "      <td>1.102872e+06</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>740.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.121170e+05</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>9.386720e+05</td>\n",
       "      <td>-3.834600e+04</td>\n",
       "      <td>1.002672e+06</td>\n",
       "      <td>8.212500e+07</td>\n",
       "      <td>3.620960e+05</td>\n",
       "      <td>7.995250e+04</td>\n",
       "      <td>1.137840e+05</td>\n",
       "      <td>2.093263e+06</td>\n",
       "      <td>2.547724e+06</td>\n",
       "      <td>1.002370e+06</td>\n",
       "      <td>-7.500975e+04</td>\n",
       "      <td>2.949847e+06</td>\n",
       "      <td>2634.750000</td>\n",
       "      <td>145.500000</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>1888.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>-8.330000e+02</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>8.392500e+07</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>4.345095e+08</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>5521.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             salary         bonus  long_term_incentive  deferred_income  \\\n",
       "count  9.500000e+01  8.200000e+01         6.600000e+01     4.900000e+01   \n",
       "mean   5.621943e+05  2.374235e+06         1.470361e+06    -1.140475e+06   \n",
       "std    2.716369e+06  1.071333e+07         5.942759e+06     4.025406e+06   \n",
       "min    4.770000e+02  7.000000e+04         6.922300e+04    -2.799289e+07   \n",
       "25%    2.118160e+05  4.312500e+05         2.812500e+05    -6.948620e+05   \n",
       "50%    2.599960e+05  7.693750e+05         4.420350e+05    -1.597920e+05   \n",
       "75%    3.121170e+05  1.200000e+06         9.386720e+05    -3.834600e+04   \n",
       "max    2.670423e+07  9.734362e+07         4.852193e+07    -8.330000e+02   \n",
       "\n",
       "       deferral_payments  loan_advances         other      expenses  \\\n",
       "count       3.900000e+01   4.000000e+00  9.300000e+01  9.500000e+01   \n",
       "mean        1.642674e+06   4.196250e+07  9.190650e+05  1.087289e+05   \n",
       "std         5.161930e+06   4.708321e+07  4.589253e+06  5.335348e+05   \n",
       "min        -1.025000e+05   4.000000e+05  2.000000e+00  1.480000e+02   \n",
       "25%         8.157300e+04   1.600000e+06  1.215000e+03  2.261400e+04   \n",
       "50%         2.274490e+05   4.176250e+07  5.238200e+04  4.695000e+04   \n",
       "75%         1.002672e+06   8.212500e+07  3.620960e+05  7.995250e+04   \n",
       "max         3.208340e+07   8.392500e+07  4.266759e+07  5.235198e+06   \n",
       "\n",
       "       director_fees  total_payments  exercised_stock_options  \\\n",
       "count   1.700000e+01    1.250000e+02             1.020000e+02   \n",
       "mean    1.668049e+05    5.081526e+06             5.987054e+06   \n",
       "std     3.198914e+05    2.906172e+07             3.106201e+07   \n",
       "min     3.285000e+03    1.480000e+02             3.285000e+03   \n",
       "25%     9.878400e+04    3.944750e+05             5.278862e+05   \n",
       "50%     1.085790e+05    1.101393e+06             1.310814e+06   \n",
       "75%     1.137840e+05    2.093263e+06             2.547724e+06   \n",
       "max     1.398517e+06    3.098866e+08             3.117640e+08   \n",
       "\n",
       "       restricted_stock  restricted_stock_deferred  total_stock_value  \\\n",
       "count      1.100000e+02               1.800000e+01       1.260000e+02   \n",
       "mean       2.321741e+06               1.664106e+05       6.773957e+06   \n",
       "std        1.251828e+07               4.201494e+06       3.895777e+07   \n",
       "min       -2.604490e+06              -7.576788e+06      -4.409300e+04   \n",
       "25%        2.540180e+05              -3.896218e+05       4.945102e+05   \n",
       "50%        4.517400e+05              -1.469750e+05       1.102872e+06   \n",
       "75%        1.002370e+06              -7.500975e+04       2.949847e+06   \n",
       "max        1.303223e+08               1.545629e+07       4.345095e+08   \n",
       "\n",
       "        to_messages  from_messages  from_poi_to_this_person  \\\n",
       "count     86.000000      86.000000                86.000000   \n",
       "mean    2073.860465     608.790698                64.895349   \n",
       "std     2582.700981    1841.033949                86.979244   \n",
       "min       57.000000      12.000000                 0.000000   \n",
       "25%      541.250000      22.750000                10.000000   \n",
       "50%     1211.000000      41.000000                35.000000   \n",
       "75%     2634.750000     145.500000                72.250000   \n",
       "max    15149.000000   14368.000000               528.000000   \n",
       "\n",
       "       from_this_person_to_poi  shared_receipt_with_poi  \n",
       "count                86.000000                86.000000  \n",
       "mean                 41.232558              1176.465116  \n",
       "std                 100.073111              1178.317641  \n",
       "min                   0.000000                 2.000000  \n",
       "25%                   1.000000               249.750000  \n",
       "50%                   8.000000               740.500000  \n",
       "75%                  24.750000              1888.250000  \n",
       "max                 609.000000              5521.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information gleamed above we can see that the poi field is a True or False and all the rest of the values are in float numbers.  There are 146 rows with each row being a different person.  \n",
    "\n",
    "All the NaNs in the financial fields are accutally 0 not unknown quantites according to the [official pdf documentation.](https://github.com/udacity/ud120-projects/blob/master/final_project/enron61702insiderpay.pdf)  The NaNs in the email data is unknown information.  I will replace the NaNs in the financial data with 0 but will fill in the NaNs for the email data with the mean of the column grouped by person of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# Fill in the NaN payment and stock values with zero \n",
    "df[payment_columns] = df[payment_columns].fillna(0)\n",
    "df[stock_columns] = df[stock_columns].fillna(0)\n",
    "\n",
    "# Create a poi dataframe and nonpoi dataframe\n",
    "df_poi = df[df[\"poi\"]]\n",
    "df_nonpoi = df[df['poi'] == False]\n",
    "# Fill in the NaN email values with column mean in the poi dataframe\n",
    "df_poi[email_columns] = df_poi[email_columns].fillna(df_poi[email_columns].mean())\n",
    "df_nonpoi[email_columns] = df_nonpoi[email_columns].fillna(df_nonpoi[email_columns].mean())\n",
    "# update the df with new poi dataframe and nonpoi dataframe\n",
    "df = df_poi.append(df_nonpoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check for financial errors easily by seeing if  all the finacial columns add up to the total columns for total payments of total stock values.  If we find any we will enter in the correct data from the [official pdf documentation.](https://github.com/udacity/ud120-projects/blob/master/final_project/enron61702insiderpay.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find any rows that don't add up to the total_payments or total_stock_value.\n",
    "# These will be errors.\n",
    "errors_payment_columns = (df[df[payment_columns[:-1]].sum(axis='columns') != df['total_payments']])\n",
    "errors_stock_columns = (df[df[stock_columns[:-1]].sum(axis='columns') != df['total_stock_value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>58.5</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1058.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>463.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poi  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT     False     0.0    0.0                  0.0              0.0   \n",
       "BHATNAGAR SANJAY  False     0.0    0.0                  0.0              0.0   \n",
       "\n",
       "                  deferral_payments  loan_advances     other  expenses  \\\n",
       "BELFER ROBERT             -102500.0            0.0       0.0       0.0   \n",
       "BHATNAGAR SANJAY                0.0            0.0  137864.0       0.0   \n",
       "\n",
       "                  director_fees  total_payments  exercised_stock_options  \\\n",
       "BELFER ROBERT            3285.0        102500.0                   3285.0   \n",
       "BHATNAGAR SANJAY       137864.0      15456290.0                2604490.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred  \\\n",
       "BELFER ROBERT                  0.0                    44093.0   \n",
       "BHATNAGAR SANJAY        -2604490.0                 15456290.0   \n",
       "\n",
       "                  total_stock_value  to_messages  from_messages  \\\n",
       "BELFER ROBERT              -44093.0  2007.111111     668.763889   \n",
       "BHATNAGAR SANJAY                0.0   523.000000      29.000000   \n",
       "\n",
       "                  from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "BELFER ROBERT                        58.5                36.277778   \n",
       "BHATNAGAR SANJAY                      0.0                 1.000000   \n",
       "\n",
       "                  shared_receipt_with_poi  \n",
       "BELFER ROBERT                 1058.527778  \n",
       "BHATNAGAR SANJAY               463.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_payment_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>58.5</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1058.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>463.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poi  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT     False     0.0    0.0                  0.0              0.0   \n",
       "BHATNAGAR SANJAY  False     0.0    0.0                  0.0              0.0   \n",
       "\n",
       "                  deferral_payments  loan_advances     other  expenses  \\\n",
       "BELFER ROBERT             -102500.0            0.0       0.0       0.0   \n",
       "BHATNAGAR SANJAY                0.0            0.0  137864.0       0.0   \n",
       "\n",
       "                  director_fees  total_payments  exercised_stock_options  \\\n",
       "BELFER ROBERT            3285.0        102500.0                   3285.0   \n",
       "BHATNAGAR SANJAY       137864.0      15456290.0                2604490.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred  \\\n",
       "BELFER ROBERT                  0.0                    44093.0   \n",
       "BHATNAGAR SANJAY        -2604490.0                 15456290.0   \n",
       "\n",
       "                  total_stock_value  to_messages  from_messages  \\\n",
       "BELFER ROBERT              -44093.0  2007.111111     668.763889   \n",
       "BHATNAGAR SANJAY                0.0   523.000000      29.000000   \n",
       "\n",
       "                  from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "BELFER ROBERT                        58.5                36.277778   \n",
       "BHATNAGAR SANJAY                      0.0                 1.000000   \n",
       "\n",
       "                  shared_receipt_with_poi  \n",
       "BELFER ROBERT                 1058.527778  \n",
       "BHATNAGAR SANJAY               463.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_stock_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct 2 error values in order taken from the official financial PDF\n",
    "fixed_bel_rob = [0, 0, 0, -102500, 0, 0, 0, 3285, 102500, 3285, 0, 44093, -44093, 0]\n",
    "fixed_bha_san = [0, 0, 0, 0, 0, 0, 0, 137864, 0, 137864, 15456290, 2604490, -2604490, 15456290]\n",
    "# Putting the fixed values into the correct rows\n",
    "df.loc[\"BELFER ROBERT\", 1:15] = fixed_bel_rob\n",
    "df.loc[\"BHATNAGAR SANJAY\", 1:15] = fixed_bha_san"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any more errors in payment_columns\n",
    "len(df[df[payment_columns[:-1]].sum(axis='columns') != df['total_payments']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any more errors in the stock_columns\n",
    "len(df[df[stock_columns[:-1]].sum(axis='columns') != df['total_stock_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Revove Outliers </h2>\n",
    "\n",
    "In looking for and removing outliers I will be looking maining at non person's of interest.  I do not want to remove any persons of interest from the data set.  I can look at the Interquartile Range.  Either lower thatn the first quartile minus 1.5 times the IQR or above the third quartile plus 1.5 times the IQR.  I will count the outliers of each non POI and see if they need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOTAL                 14\n",
       "FREVERT MARK A        12\n",
       "BAXTER JOHN C          8\n",
       "LAVORATO JOHN J        8\n",
       "KEAN STEVEN J          7\n",
       "WHALLEY LAWRENCE G     7\n",
       "HAEDICKE MARK E        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "IQR = df.quantile(q=0.75) - df.quantile(q=0.25)\n",
    "first_quartile = df.quantile(q=0.25)\n",
    "third_quartile = df.quantile(q=0.75)\n",
    "outliers = df[(df>(third_quartile + 1.5*IQR) ) | (df<(first_quartile - 1.5*IQR) )].count(axis=1)\n",
    "\n",
    "poi = df[df[\"poi\"]].index\n",
    "\n",
    "for o in outliers.keys():\n",
    "    if o in poi:\n",
    "        del outliers[o]\n",
    "\n",
    "outliers.sort_values(axis=0, ascending=False, inplace=True)\n",
    "outliers.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that TOTAL is the highest row with outliers and since that is not a person I will remove it.  I can remove the next 4 highest non-POI with outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removes rows TOTAL because they are not people\n",
    "df.drop(axis=0, labels=['TOTAL', 'THE TRAVEL AGENCY IN THE PARK','FREVERT MARK A', 'BAXTER JOHN C', 'LAVORATO JOHN J', 'KEAN STEVEN J'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    122\n",
       "True      18\n",
       "Name: poi, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"poi\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0L"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150L"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df==0].count().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves me with 140 individuals (122 non-POI and 18 POI).  I also see that there is no nulls in my data now and that there are 1150 zeros in the dataset I will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will then scale the data using the normalization function.  Scaling creates non-dimensional features so that those features with larger units do not have an undue influence on the classifier as would be the case if the classifier uses some sort of distance measurement as a similarity metric.\n",
    "\n",
    "I will first train with the initial features of the dataset to gain a baseline to work and observe the performance of each algorithm before I start to tune.  I selected DecisionTreeClassifier, GaussianNB, KNeighborsClassifier, and Support Vector Cassifier (SVC).  I will run all the parameters on default settings.  \n",
    "\n",
    "I will be looking at precision, recall, and F1 score metrics to determine the best algorithm that will find the person of interest. \n",
    "\n",
    "Precision is the fraction of persons of interest that the algorithm predicts that are truly persons of interest.  Mathematically precision is defined as \n",
    "\n",
    "$$ precision = \\frac{true\\ positives}{true\\ positives + false\\ positives} $$\n",
    "\n",
    "Recall is the fraction of persons of interest that the algorithm identifies.  Mathematically precision is defined as\n",
    "\n",
    "\\\\[ recall = \\frac{true\\ positives}{true\\ positives + false\\ negatives} \\\\]\n",
    "\n",
    "Precision is also known as positive predictive value while recall is called the sensitivity of the classifier. A combined measured of precision and recall is the F1 score. Is it the harmonic mean of precision and recall. Mathematically, the F1 score is defined as:\n",
    "\n",
    "\\\\[ F1\\ Score = \\frac{2\\ (precision\\ x\\ recall)}{precision + recall} \\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that will print the precision df\n",
    "def print_precision(dic):\n",
    "    df = pd.DataFrame.from_dict(dic, orient='columns')\n",
    "    print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\tAccuracy: 0.83236\tPrecision: 0.40334\tRecall: 0.36200\tF1: 0.38155\tF2: 0.36958\n",
      "\tTotal predictions: 14000\tTrue positives:  724\tFalse positives: 1071\tFalse negatives: 1276\tTrue negatives: 10929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "# my_dataset = data_dict\n",
    "# Scale the dataset and send it back to a dictionary\n",
    "scaled_df = df.copy()\n",
    "scaled_df.iloc[:,1:] = scale(scaled_df.iloc[:,1:])\n",
    "my_dataset = scaled_df.to_dict(orient='index')\n",
    "\n",
    "df_dtc = {}\n",
    "clf = DecisionTreeClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_dtc[\"dtc_1\"] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.66936\tPrecision: 0.25653\tRecall: 0.69250\tF1: 0.37437\tF2: 0.51683\n",
      "\tTotal predictions: 14000\tTrue positives: 1385\tFalse positives: 4014\tFalse negatives:  615\tTrue negatives: 7986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the classifier, GaussianNB has no parameters to tune\n",
    "df_gnb = {}\n",
    "clf = GaussianNB()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_gnb['gnb_1'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "\tAccuracy: 0.83514\tPrecision: 0.01875\tRecall: 0.00300\tF1: 0.00517\tF2: 0.00361\n",
      "\tTotal predictions: 14000\tTrue positives:    6\tFalse positives:  314\tFalse negatives: 1994\tTrue negatives: 11686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_knc = {}\n",
    "clf = KNeighborsClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_knc['knc_1'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\tAccuracy: 0.85714\tPrecision: 0.50000\tRecall: 0.00150\tF1: 0.00299\tF2: 0.00187\n",
      "\tTotal predictions: 14000\tTrue positives:    3\tFalse positives:    3\tFalse negatives: 1997\tTrue negatives: 11997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_svc = {}\n",
    "clf = SVC()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_svc['svc_1'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dtc_1\n",
      "Accuracy   0.832357\n",
      "F1         0.381555\n",
      "Precision  0.403343\n",
      "Recall     0.362000\n",
      "              gnb_1\n",
      "Accuracy   0.669357\n",
      "F1         0.374375\n",
      "Precision  0.256529\n",
      "Recall     0.692500\n",
      "              knc_1\n",
      "Accuracy   0.835143\n",
      "F1         0.005172\n",
      "Precision  0.018750\n",
      "Recall     0.003000\n",
      "              svc_1\n",
      "Accuracy   0.857143\n",
      "F1         0.002991\n",
      "Precision  0.500000\n",
      "Recall     0.001500\n"
     ]
    }
   ],
   "source": [
    "print_precision(df_dtc)\n",
    "print_precision(df_gnb)\n",
    "print_precision(df_knc)\n",
    "print_precision(df_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the different algorithms' initial results we see that the decision tree classifer performed the best overall on all three metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create new features </h2>\n",
    "\n",
    "I will create some new features that should help performace.  I will have four new features.  I believe that the ratio of emails from a POI, to a POI, or shared with POI will be a great use.  I will also see if the salary ratio of the individual with total payments recieved from the company will help.  I will fill all NaN in these new columns with 0.  I will then see if the new features improve the metrics in the 4 algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "df[\"from_poi_ratio\"] = df[\"from_poi_to_this_person\"] / df[\"from_messages\"]\n",
    "df[\"to_poi_ratio\"] = df[\"from_this_person_to_poi\"] / df[\"to_messages\"]\n",
    "df[\"shared_poi_ratio\"] = df[\"shared_receipt_with_poi\"] / df[\"to_messages\"]\n",
    "df[\"salary_ratio\"] = df[\"salary\"] / df[\"total_payments\"]\n",
    "\n",
    "features_list.append('to_poi_ratio')\n",
    "features_list.append('from_poi_ratio')\n",
    "features_list.append('shared_poi_ratio')\n",
    "features_list.append('salary_ratio')\n",
    "\n",
    "df.fillna(value=0, inplace=True)\n",
    "df = df.replace('inf', 0)\n",
    "\n",
    "# Scale the dataset and send it back to a dictionary\n",
    "scaled_df = df.copy()\n",
    "scaled_df.iloc[:,1:] = scale(scaled_df.iloc[:,1:])\n",
    "my_dataset = scaled_df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Validation </h3>\n",
    "\n",
    "To validate the algorithms chosen I will be using cross-validation in the tester.py script.  Cross-validation will take the data and perfom multiple splits.  Each split will be different training and testing sets.  The classifier is then fit with the training set and tested on the testing set.  The classifier is then trained and tested on different sets.  This process continues for the number of splits made on the data set.  Cross-validation prevents the classifier from training and testing on the same data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\tAccuracy: 0.83693\tPrecision: 0.41073\tRecall: 0.32550\tF1: 0.36318\tF2: 0.33959\n",
      "\tTotal predictions: 14000\tTrue positives:  651\tFalse positives:  934\tFalse negatives: 1349\tTrue negatives: 11066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Create and test the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_dtc['dtc_2'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.68293\tPrecision: 0.26398\tRecall: 0.68200\tF1: 0.38063\tF2: 0.51796\n",
      "\tTotal predictions: 14000\tTrue positives: 1364\tFalse positives: 3803\tFalse negatives:  636\tTrue negatives: 8197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the Gaussian Naive Bayes Classifier\n",
    "clf = GaussianNB()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_gnb['gnb_2'] = tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "\tAccuracy: 0.85786\tPrecision: 0.51397\tRecall: 0.09200\tF1: 0.15606\tF2: 0.11007\n",
      "\tTotal predictions: 14000\tTrue positives:  184\tFalse positives:  174\tFalse negatives: 1816\tTrue negatives: 11826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the KMeans Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_knc['knc_2'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\tAccuracy: 0.85657\tPrecision: 0.49625\tRecall: 0.26450\tF1: 0.34508\tF2: 0.29175\n",
      "\tTotal predictions: 14000\tTrue positives:  529\tFalse positives:  537\tFalse negatives: 1471\tTrue negatives: 11463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the Support Vector Classifier\n",
    "clf = SVC(kernel=\"linear\")\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_svc['svc_2'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dtc_1     dtc_2\n",
      "Accuracy   0.832357  0.836929\n",
      "F1         0.381555  0.363180\n",
      "Precision  0.403343  0.410726\n",
      "Recall     0.362000  0.325500\n",
      "              gnb_1     gnb_2\n",
      "Accuracy   0.669357  0.682929\n",
      "F1         0.374375  0.380633\n",
      "Precision  0.256529  0.263983\n",
      "Recall     0.692500  0.682000\n",
      "              knc_1     knc_2\n",
      "Accuracy   0.835143  0.857857\n",
      "F1         0.005172  0.156064\n",
      "Precision  0.018750  0.513966\n",
      "Recall     0.003000  0.092000\n",
      "              svc_1     svc_2\n",
      "Accuracy   0.857143  0.856571\n",
      "F1         0.002991  0.345075\n",
      "Precision  0.500000  0.496248\n",
      "Recall     0.001500  0.264500\n"
     ]
    }
   ],
   "source": [
    "print_precision(df_dtc)\n",
    "print_precision(df_gnb)\n",
    "print_precision(df_knc)\n",
    "print_precision(df_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results after the new features were added the two best performing algorithms are decision tree classifier and SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tune Algorithms </h2>\n",
    "\n",
    "When you start to tune your algorithms you are starting to optimize the settings in the algorithm to achieve maximum performance on the given data.  Algorithms are a list of rules that produce a result and tuning can be a way of altering the rules to produce better classifications.  You can either tune manually by selecting different configurations, performing cross-validation, and then selecting the settings that give you the highest performance or you can automate the algorithm to select the best settings using GridSearchCV.  GridSearchCV uses a number of combinations of parameters determined by the user to test the algorithm and returns the maximized performance perameters.\n",
    "\n",
    "I will be choosing the DecisionTreeClassifier and SVC to tune and compare.  The first thing I will do is find the feature importances of the DecissionTree.  The higher the score the more important the feature.  This score is computed as the normalized total reduciton of the criterion brought by the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.22631578947368439, 'total_payments'),\n",
       " (0.17026292251200423, 'shared_poi_ratio'),\n",
       " (0.113953488372093, 'to_poi_ratio'),\n",
       " (0.11078811369509041, 'bonus'),\n",
       " (0.10631358305776914, 'from_poi_ratio'),\n",
       " (0.087519136837501288, 'exercised_stock_options'),\n",
       " (0.071220930232558127, 'to_messages'),\n",
       " (0.067303479570480967, 'other'),\n",
       " (0.04632255624881846, 'restricted_stock'),\n",
       " (0.0, 'total_stock_value'),\n",
       " (0.0, 'shared_receipt_with_poi'),\n",
       " (0.0, 'salary_ratio'),\n",
       " (0.0, 'salary'),\n",
       " (0.0, 'restricted_stock_deferred'),\n",
       " (0.0, 'long_term_incentive'),\n",
       " (0.0, 'loan_advances'),\n",
       " (0.0, 'from_this_person_to_poi'),\n",
       " (0.0, 'from_poi_to_this_person'),\n",
       " (0.0, 'from_messages'),\n",
       " (0.0, 'expenses'),\n",
       " (0.0, 'director_fees'),\n",
       " (0.0, 'deferred_income'),\n",
       " (0.0, 'deferral_payments')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "tree_importance = clf.feature_importances_\n",
    "tree_features = zip(tree_importance, features_list[1:])\n",
    "tree_features.sort(reverse=True)\n",
    "tree_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "n_features = np.arange(1, len(features_list))\n",
    "\n",
    "# Create a pipeline with feature selection and classification\n",
    "pipe = Pipeline([('select_features', SelectKBest()),\n",
    "                 ('classify', DecisionTreeClassifier())\n",
    "                ])\n",
    "param = [{'select_features__k': n_features}]\n",
    "\n",
    "# Use GridSearchCV to find the optimal number of features\n",
    "clf = GridSearchCV(pipe, param_grid=param, scoring='f1', cv = 10)\n",
    "clf.fit(features, labels);\n",
    "# number of best parameters found by GridSearchCV\n",
    "\n",
    "best_params = clf.best_params_\n",
    "best_k = best_params['select_features__k']\n",
    "best_k\n",
    "best_k = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('select_features', SelectKBest(k=11, score_func=<function f_classif at 0x0855BE70>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.83071\tPrecision: 0.39118\tRecall: 0.33250\tF1: 0.35946\tF2: 0.34278\n",
      "\tTotal predictions: 14000\tTrue positives:  665\tFalse positives: 1035\tFalse negatives: 1335\tTrue negatives: 10965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with feature selection and classification\n",
    "pipe = Pipeline([('select_features', SelectKBest(k=best_k)),\n",
    "                 ('classify', DecisionTreeClassifier())\n",
    "                ])\n",
    "\n",
    "# Create and test the Decision Tree Classifier\n",
    "tester.dump_classifier_and_data(pipe, my_dataset, features_list)\n",
    "df_dtc['dtc_3'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('select_features', SelectKBest(k=11, score_func=<function f_classif at 0x0855BE70>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'classify__min_samples_split': [2, 4, 6, 8, 10, 20], 'classify__max_depth': [None, 5, 10, 15, 20], 'classify__max_features': [None, 'sqrt', 'log2', 'auto'], 'classify__criterion': ['entropy', 'gini'], 'classify__min_samples_leaf': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with feature selection and classifier\n",
    "pipe = Pipeline([('select_features', SelectKBest(k=best_k)),\n",
    "                 ('classify', DecisionTreeClassifier()),\n",
    "                ])\n",
    "\n",
    "# Define the configuration of parameters to test with the Decision Tree Classifier\n",
    "param = dict(classify__criterion = ['entropy', 'gini'],\n",
    "             classify__max_depth = [None, 5, 10, 15, 20],\n",
    "             classify__min_samples_split = [2, 4, 6, 8, 10, 20],\n",
    "             classify__min_samples_leaf = [1, 2, 3],\n",
    "             classify__max_features = [None, 'sqrt', 'log2', 'auto'])\n",
    "\n",
    "# Use GridSearchCV to find the optimal hyperparameters for the classifier\n",
    "clf = GridSearchCV(pipe, param_grid = param, scoring='f1', cv=10)\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5680952380952381"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify__criterion': 'entropy',\n",
       " 'classify__max_depth': None,\n",
       " 'classify__max_features': 'auto',\n",
       " 'classify__min_samples_leaf': 1,\n",
       " 'classify__min_samples_split': 2}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best algorithm hyperparameters for the Decision Tree\n",
    "best_params =clf.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('select_features', SelectKBest(k=11, score_func=<function f_classif at 0x0855BE70>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.83900\tPrecision: 0.42913\tRecall: 0.38450\tF1: 0.40559\tF2: 0.39267\n",
      "\tTotal predictions: 14000\tTrue positives:  769\tFalse positives: 1023\tFalse negatives: 1231\tTrue negatives: 10977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the classifier with the optimal hyperparameters as found by GridSearchCV\n",
    "clf = Pipeline([\n",
    "    ('select_features', SelectKBest(k=11)),\n",
    "    ('classify', DecisionTreeClassifier(criterion=best_params['classify__criterion'], \n",
    "                                        max_depth=best_params['classify__max_depth'], \n",
    "                                        max_features=best_params['classify__max_features'], \n",
    "                                        min_samples_leaf=best_params['classify__min_samples_leaf'], \n",
    "                                        min_samples_split=best_params['classify__min_samples_split']))\n",
    "])\n",
    "\n",
    "# Test the Decision Tree Classifier with best parameters using tester.py\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_dtc['dtc_4'] = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dtc_1     dtc_2     dtc_3     dtc_4\n",
      "Accuracy   0.832357  0.836929  0.830714  0.839000\n",
      "F1         0.381555  0.363180  0.359459  0.405591\n",
      "Precision  0.403343  0.410726  0.391176  0.429129\n",
      "Recall     0.362000  0.325500  0.332500  0.384500\n"
     ]
    }
   ],
   "source": [
    "print_precision(df_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV and SelectKBest I was able to determine that using the 11 best perameters in the DecisionTreeClassider provided the best results.  This produces an F1 score of 0.3865 which was a small improvement over the initial F1 score of 0.3770."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'classify__C': [10, 100, 1000, 10000], 'classify__kernel': ['linear', 'rbf', 'poly']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with feature selection and classifier\n",
    "pipe = Pipeline([('classify', SVC())])\n",
    "\n",
    "# Define the configuration of parameters to test with the Decision Tree Classifier\n",
    "param = dict(classify__C=[10, 100, 1000, 10000], \n",
    "             classify__kernel=['linear', 'rbf', 'poly'])\n",
    "\n",
    "# Use GridSearchCV to find the optimal hyperparameters for the classifier\n",
    "clf = GridSearchCV(pipe, param_grid = param, scoring='f1', cv=10)\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify__C': 100, 'classify__kernel': 'linear'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = clf.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('classify', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.85407\tPrecision: 0.48900\tRecall: 0.47800\tF1: 0.48344\tF2: 0.48016\n",
      "\tTotal predictions: 14000\tTrue positives:  956\tFalse positives:  999\tFalse negatives: 1044\tTrue negatives: 11001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('classify', SVC(C=best_params['classify__C'],\n",
    "                                 kernel=best_params['classify__kernel']))])\n",
    "\n",
    "# Test the Decision Tree Classifier with best parameters using tester.py\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "df_svc['svc_3'] = tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearch for the SVC algorithm we were able to raise the F1 score from 0.3450 to 0.4834.  I then compared the dtc and svc tuning results and concluded that the SVC algorithm was superiour in every metric to the Decision Tree Classifier and will be using the SVC algorithm for the final algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              svc_1     svc_2     svc_3\n",
      "Accuracy   0.857143  0.856571  0.854071\n",
      "F1         0.002991  0.345075  0.483439\n",
      "Precision  0.500000  0.496248  0.489003\n",
      "Recall     0.001500  0.264500  0.478000\n",
      "              dtc_1     dtc_2     dtc_3     dtc_4\n",
      "Accuracy   0.832357  0.836929  0.830714  0.839000\n",
      "F1         0.381555  0.363180  0.359459  0.405591\n",
      "Precision  0.403343  0.410726  0.391176  0.429129\n",
      "Recall     0.362000  0.325500  0.332500  0.384500\n"
     ]
    }
   ],
   "source": [
    "print_precision(df_svc)\n",
    "print_precision(df_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
